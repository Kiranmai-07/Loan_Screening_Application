# -*- coding: utf-8 -*-
"""case_study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10dckZDedxLhOelNmQQdL_yASx5rT3eTM

#JPMorgan Chase CCB Case Study Submission
###Name: Kancharla Kiranmai

###Question-1 :
####As a decision maker, looking into these given booked accounts, how would you want to take a decision to approve/ decline the same applications again in future? What would be your screening criterion(s), if any?
<br>
By looking into previous booked account and checking their loan status,delinquency, details of total payment, any remaining outstanding principal for total amount funded, current dti, lti, employment length and income values to approve/decline loan.
<br>
For future applications my screening criterions would be the following:
<br>
<br>
Previous Recoveries: Applicants with 0 recoveries are preffered
<br>
<br>
Number of Inquiries in the Last 6 Months:  0 or 1 inquiry is prefered
<br>
<br>
Debt-to-Income Ratio (DTI): DTI less than or 13.25 is preffered
<br>
<br>
Minimum FICO Score: A FICO score around 639+ is preferred
<br>
<br>
Loan-to-Income (LTI) Ratio: LTI less than or around 0.16 is preferred.
<br>
<br>
Total Credit Revolving Balance: This indicates the total amount of credit currently in use. Lower balances are preferable.
<br>
<br>
Minimum Annual Income: Higher income levels suggest a better ability to repay the loan.
<br>
<br>
Employment Length: employment length of min 4 yrs is preffered
<br>
<br>
Public Records: The absence of negative public records (e.g., bankruptcies, foreclosures) is preferable.
<br>
<br>
Open Credit Lines: open credit accounts less than 15 are preffered
<br>
<br>
Bankcard Accounts Utilization (>75%): Between 0 and 2 are preffered
<br>
<br>
Recent History of Defaults or Late Payments: minimum last delinquency around 33 months are preffered
<br>
<br>


###Question-2 :
#####Please provide data driven rationale to substantiate the appropriateness of the characteristics you have identified in the screening logic
<br>
Following are the data attributes that substantiate the appropriateness of the characteristics identified in the screening logic:
<br>
recoveries,
 fico_score,
loan_amnt,
inq_last_6mths,
month_since_oldest_tl,
interest_rate,
total_acc,
mths_since_last_record,
term,
number_bc_gt_75,
installment,
revol_bal,
out_prncp,
lti,
emp_length,
dti,
annual_inc,
mths_since_last_delinq,
open_acc,
collection_recovery_fee,
revol_utilization,
delinq_2yrs,
pub_rec,
home ownership,
pub_rec_bankruptcies.
<br>
<br>

###Question- 3 :
#####Given that you have a decision engine, which helps you to take a call based on the given data, how would you identify if your process has an unintentional bias and discriminate your customers based on some of the sensitive attributes, available in this dataset?
<br>
 I will also train my model with sensitive attributes(race and gender) and look onto the feature importance values of the features and identify whether the model has any unintentional bias.
 <br>
 From the feature imporatance values of the created model below clearly race and gender has very less importance values which states that loan screening is not influenced by those features and model is not biased towards sensitive attributes.
<br>
<br>
<table>
   <tr>
      <th></th>
     <th>Importance</th>
    </tr>
    <tr>
      <td>recoveries</td>
      <td>0.821226</td>
    </tr>
    <tr>
      <td>fico_score</td>
      <td>0.078321</td>
    </tr>
    <tr>
      <td>inq_last_6mths</td>
      <td>0.031843</td>
    </tr>
    <tr>
      <td>month_since_oldest_tl</td>
      <td> 0.024720</td>
    </tr>
     <tr>
      <td>interest_rate</td>
      <td>0.011899</td>
    </tr>
     <tr>
      <td>total_acc</td>
      <td>0.010493</td>
    </tr>
     <tr>
      <td>mths_since_last_record</td>
      <td>0.005331</td>
    </tr>
    <tr>
      <td>term</td>
      <td>0.004705</td>
    </tr>
    <tr>
      <td>number_bc_gt_75</td>
      <td>0.002983</td>
    </tr>
    <tr>
      <td>loan_amnt</td>
      <td>  0.002361</td>
    </tr>
    <tr>
      <td>revol_bal</td>
      <td> 0.001147</td>
    </tr>
     <tr>
      <td>lti</td>
      <td> 0.001147</td>
    </tr>
     <tr>
      <td>emp_length</td>
      <td>0.000592</td>
    </tr>
    <tr>
      <td>annual_inc</td>
      <td> 0.000444</td>
    </tr>
    <tr>
      <td>dti</td>
      <td> 0.000422</td>
    </tr>
    <tr>
      <td>mths_since_last_delinq</td>
      <td>0.000351</td>
    </tr>
    <tr>
      <td>home_ownership</td>
      <td>0.000318</td>
    </tr>
    <tr>
      <td>revol_utilization</td>
      <td>0.000263</td>
    </tr>
    <tr>
      <td>installment</td>
      <td>0.000242</td>
    </tr>
    <tr>
      <td>open_acc</td>
      <td>0.000205</td>
    </tr>
    <tr>
      <td>out_prncp</td>
      <td>0.000099</td>
    </tr>
    <tr>
      <td>gender</td>
      <td> 0.000080</td>
    </tr>
    <tr>
      <td>delinq_2yrs</td>
      <td>0.000075</td>
    </tr>
    <tr>
      <td>pub_rec_bankruptcies</td>
      <td>0.000048 </td>
    </tr>
    <tr>
      <td>race_name</td>
      <td>0.000037</td>
    </tr>
     <tr>
      <td>collection_recovery_fee</td>
      <td>0.000035</td>
    </tr>
    <tr>
      <td>pub_rec </td>
      <td>0.000028</td>
    </tr>
     
  </table>
"""

from google.colab import files
uploaded = files.upload()

"""####Import Libraries"""

import io
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score
from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay,roc_curve

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

from imblearn.over_sampling import SMOTE
from collections import Counter

"""FUNCTION FOR EVALUATION METRICS OF THE REQUIRED MODEL"""

def getEvaluationMetrices(model_name,X_train,y_train,X_test,y_test,seed=101,feature_imp=""):

  if model_name == "LR":
    scaler = StandardScaler()
    scaled_X_train = scaler.fit_transform(X_train)
    scaled_X_test = scaler.transform(X_test)
    scaled_X_train
    model = LogisticRegression()

  elif model_name == "DT":
    model = DecisionTreeClassifier(max_depth=12, random_state=seed)

  elif model_name == "RF":
    model = RandomForestClassifier(n_estimators=100,max_depth=12,random_state=seed)

  else :
    model = GradientBoostingClassifier(learning_rate=0.1, n_estimators=125, max_depth=5)
    model.fit(X_train, y_train)

  if model_name == "LR":
    model.fit(scaled_X_train, y_train)
    train_preds = model.predict(scaled_X_train)
    y_preds = model.predict(scaled_X_test)
    RocCurveDisplay.from_predictions(y_true=y_test, y_pred=y_preds)
    plt.show()
  else :
    model.fit(X_train, y_train)
    train_preds = model.predict(X_train)
    y_preds = model.predict(X_test)

  acc_train = accuracy_score(y_train,train_preds)
  acc_val = accuracy_score(y_test,y_preds)
  print(f'Training accuracy : {acc_train*100}%')
  print(f'Testing accuracy : {acc_val*100}%')
  print()
  disp=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_true=y_test, y_pred=y_preds))
  disp.plot()
  plt.show()
  # print(pd.crosstab(y_test,y_preds))
  print()
  print(classification_report(y_true=y_test, y_pred=y_preds))
  if(feature_imp=="feature_imp"):
    feats = pd.DataFrame(index=X.columns,data=model.feature_importances_,columns=['Importance'])
    imp_feats = feats[feats['Importance']>0]
    print(imp_feats.sort_values(by='Importance',ascending=False))
  return

df = pd.read_csv('loan_dataset_final.csv', encoding='latin1')
df.head()

#replace emp length with numbers
replacement_mapping = {'< 1 year':0,'1 year':1, '2 years':2, '3 years':3, '4 years':4,
                       '5 years':5, '6 years':6, '7 years':7, '8 years':8, '9 years':8, '10 years':10,'10+ years':10}
df['emp_length'] = df['emp_length'].replace(replacement_mapping)
#replace term length with numbers
replacement_mapping2 = {'60 months':60,'36 months':36}
df['term'] = df['term'].replace(replacement_mapping2)

df.isna().sum()

"""filling null values"""

#filling null values with median is as median is less affected by outliers
df['emp_length']=df['emp_length'].fillna(df['emp_length'].median())
df['delinq_2yrs']=df['delinq_2yrs'].fillna(df['delinq_2yrs'].median())
df['inq_last_6mths']=df['inq_last_6mths'].fillna(df['inq_last_6mths'].median())
df['annual_inc']=df['annual_inc'].fillna(df['annual_inc'].median())
df['mths_since_last_delinq']=df['mths_since_last_delinq'].fillna(df['mths_since_last_delinq'].median())
df['mths_since_last_record']=df['mths_since_last_record'].fillna(df['mths_since_last_record'].median())
df['open_acc']=df['open_acc'].fillna(df['open_acc'].median())
df['pub_rec']=df['pub_rec'].fillna(df['pub_rec'].median())
df['total_acc']=df['total_acc'].fillna(df['total_acc'].median())
df['collections_12_mths_ex_med']=df['collections_12_mths_ex_med'].fillna(df['collections_12_mths_ex_med'].median())
df['pub_rec_bankruptcies']=df['pub_rec_bankruptcies'].fillna(df['pub_rec_bankruptcies'].median())
df['revol_utilization']=df['revol_utilization'].fillna(df['revol_utilization'].median())
df['lti']=df['loan_amnt']/df['annual_inc']
df['month_since_oldest_tl'] =df['month_since_oldest_tl'].fillna(df['month_since_oldest_tl'].median())

df['loan_status'].value_counts()

"""## Adding target column

From the previous booked account setting approve loan if loan status is 'Fully Paid', 'Current' or 'Does not meet the credit policy. Status:Fully Paid' to train the model accordingly
"""

condition= df['loan_status'].isin(['Fully Paid','Current','Does not meet the credit policy. Status:Fully Paid'])
df['target']=condition.astype(int)
#If target is 1 then approve loan else decline
df.head()

"""Dropping the not required columns to train model
<br>
<br>
"""

cols=['id','member_id','funded_amnt','funded_amnt_inv','emp_title','issue_d','verification_status', 'loan_status',
         'pymnt_plan', 'desc', 'title','out_prncp_inv',  'total_pymnt','total_pymnt_inv', 'total_rec_prncp', 'total_rec_int','addr_state','purpose',
       'total_rec_late_fee','collections_12_mths_ex_med']
df=df.drop(columns=cols)

df.head()

"""Encode Object Type
<br>
<br>
"""

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

# Apply the label encoder to each non-numeric column
for column in df.select_dtypes(include='object').columns:
    df[column] = label_encoder.fit_transform(df[column])

df.head()

df.isna().sum()

"""Training the data with Logistic regression, DTC, RFC and GBC"""

X= df.drop(columns=['target'])
y=df['target']
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,  random_state=101)
getEvaluationMetrices("LR",X_train,y_train,X_test,y_test)

getEvaluationMetrices("DT",X_train,y_train,X_test,y_test)

getEvaluationMetrices("RF",X_train,y_train,X_test,y_test)

getEvaluationMetrices("GBC",X_train,y_train,X_test,y_test)

"""Gradient Boosting Classification gave the best accuracy and metric values."""

df['target'].value_counts()

"""Even the data is Imbalanced Data our model metric values are pretty good for both the classes(approve/decline). Lets also make model using UnderSampling or OverSampling to overcome Imbalance

##Undersampling
"""

minority_class_length= len(df[df['target']==0])
print(minority_class_length)
#storing majority class indices and minority class indices
majority_class_indices =(df[df['target']==1]).index
minority_class_indices =(df[df['target']==0]).index
print(majority_class_indices)
#choosing majority class indices randomly of size minority class
random_maj_indices= np.random.choice(majority_class_indices,minority_class_length,replace=False)
#concatenate indices
under_sample_indices= np.concatenate([minority_class_indices,random_maj_indices])
#make the data frame
under_sample= df.loc[under_sample_indices]

sns.countplot(x='target',data=under_sample)

"""### Performing Logistic Regression, Decision tree Classification, Random forest Classification and GBC on Undersampled Dataset"""

X= under_sample.drop(columns=['target'])
y=under_sample['target']
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,  random_state=101)

getEvaluationMetrices("LR",X_train,y_train,X_test,y_test)

getEvaluationMetrices("DT",X_train,y_train,X_test,y_test)

getEvaluationMetrices("RF",X_train,y_train,X_test,y_test)

getEvaluationMetrices("GBC",X_train,y_train,X_test,y_test)

"""In Undersampling among all the four models(LR,DTC,RFC and GBC) Gradient Boosting Classification gave best accuracy and metric values (precision, recall and F1-score) but using Undersampling for loan screening is a draw back as we randomly chose majority class indices, the model we cant cover all the cases. The model dont perform well on a new case data.

##OverSampling

Using SMOTE for OverSampling
"""

smote = SMOTE(random_state=101,sampling_strategy=1.0)
X= df.drop(columns=['target'])
y=df['target']
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,  random_state=101)
smote = SMOTE(random_state=101, sampling_strategy=1.0)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print("Before Smote:", Counter(y_train))
print("After Smote:", Counter(y_train_smote))

getEvaluationMetrices("GBC", X_train_smote, y_train_smote,X_test,y_test,feature_imp="feature_imp")

"""OverSampling GBC gave the best results among all"""